{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf878fbb",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b2c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max scaling is a data preprocessing technique used to transform the data \n",
    "# within a specific range, typically between 0 and 1. The purpose of this scaling is to bring all the features to a similar \n",
    "# scale so that they do not dominate the model training process and lead to better performance in machine learning\n",
    "# algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746ff66c",
   "metadata": {},
   "source": [
    "<!-- Yes, your understanding is mostly correct. Min-max scaling is a data preprocessing technique used to transform the data within a specific range, typically between 0 and 1. The purpose of this scaling is to bring all the features to a similar scale so that they do not dominate the model training process and lead to better performance in machine learning algorithms.\n",
    "\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956cbed0",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9afe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Unit Vector technique, also known as Vector Normalization or L2 normalization, is a feature scaling method that scales\n",
    "# the values of a feature vector to have a magnitude (length) of 1. It involves dividing each data point in the feature \n",
    "# by the Euclidean norm (L2 norm) of the entire feature vector. The L2 norm of a vector is the square root of the sum of\n",
    "# the squares of its components.\n",
    "\n",
    "# The formula for calculating the unit vector (normalized) of a feature vector X = [x1, x2, ..., xn] is:\n",
    "\n",
    "# unit_vector = X / ||X||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ac447",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63be0ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA stands for Principal Component Analysis, and it is a widely used dimensionality reduction technique in the field of data\n",
    "# analysis and machine learning. The main goal of PCA is to transform a high-dimensional dataset into a lower-dimensional \n",
    "# space while preserving the most important patterns and variations in the data.\n",
    "\n",
    "# In PCA, the dimensionality reduction is achieved by identifying a new set of orthogonal axes, called principal components,\n",
    "# that capture the maximum variance in the data. The first principal component accounts for the most significant variation,\n",
    "# the second principal component accounts for the second most significant variation, and so on. By projecting the original \n",
    "# data onto a subset of these principal components, we can reduce the dimensionality of the dataset while retaining most of\n",
    "# the essential information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3d396",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3245e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA is used in data analysis and machine learning. It is used to transform a dataset with a large number of variables (features) \n",
    "# into a lower-dimensional space while preserving most of the relevant information. PCA is closely related to feature\n",
    "# extraction, and it can be utilized as a feature extraction method.\n",
    "\n",
    "# The relationship between PCA and feature extraction lies in their ability to represent data in a more compact form by \n",
    "# identifying the most informative features or combinations of features. PCA achieves this by finding the principal \n",
    "# components, which are orthogonal vectors that point in the directions of maximum variance in the data.\n",
    "\n",
    "\n",
    "\n",
    "# Suppose we have a dataset with three numerical features (x1, x2, and x3). We want to reduce it to two features using PCA.\n",
    "\n",
    "# Step 1: Standardization\n",
    "# Standardize the data to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "# Step 2: Applying PCA\n",
    "# Compute the covariance matrix and its eigenvectors and eigenvalues.\n",
    "\n",
    "# Step 3: Feature Extraction\n",
    "# Select the top two eigenvectors as the extracted features (principal components).\n",
    "\n",
    "# Step 4: Projecting Data\n",
    "# Take the dot product of the data with the selected eigenvectors to transform the data into the new lower-dimensional space.\n",
    "\n",
    "# The data has now been transformed from three dimensions to two dimensions, representing the two most significant components of the original data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e052f1e2",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8374f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the context of building a recommendation system for a food delivery service, Min-Max scaling can be used to preprocess \n",
    "# the data and ensure that the features are on a common scale. Min-Max scaling, also known as normalization, scales the \n",
    "# features to a specific range, typically between 0 and 1.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame with features: price, rating, and delivery_time\n",
    "data = {\n",
    "    'price': [10, 20, 30, 40, 50],\n",
    "    'rating': [4.5, 3.8, 4.2, 3.9, 4.7],\n",
    "    'delivery_time': [20, 35, 25, 40, 30]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8575d0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>delivery_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4.5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>3.8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>4.2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>3.9</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>4.7</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  rating  delivery_time\n",
       "0     10     4.5             20\n",
       "1     20     3.8             35\n",
       "2     30     4.2             25\n",
       "3     40     3.9             40\n",
       "4     50     4.7             30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f230527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Min-Max scaling range (0 to 1)\n",
    "min_value = 0\n",
    "max_value = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d1a806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df.columns:\n",
    "    df[feature]=(df[feature]-df[feature].min())/(df[feature].max()-df[feature].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e4bc43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>delivery_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price    rating  delivery_time\n",
       "0   0.00  0.777778           0.00\n",
       "1   0.25  0.000000           0.75\n",
       "2   0.50  0.444444           0.25\n",
       "3   0.75  0.111111           1.00\n",
       "4   1.00  1.000000           0.50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2963ee",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539879be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            PC1           PC2\n",
      "0  2.175328e+00 -1.126033e+00\n",
      "1  7.962252e-01  1.538189e+00\n",
      "2 -4.575856e-17  3.299087e-16\n",
      "3 -1.087664e+00  5.630163e-01\n",
      "4 -1.883889e+00 -9.751728e-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sample DataFrame with features: financial_data1, financial_data2, ..., market_trend1, market_trend2, ...\n",
    "data = {\n",
    "    'financial_data1': [10, 20, 30, 40, 50],\n",
    "    'financial_data2': [5, 15, 25, 35, 45],\n",
    "    'market_trend1': [1.2, 0.8, 1.0, 0.9, 1.1],\n",
    "    'market_trend2': [0.7, 0.9, 0.8, 0.6, 0.5]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separate features and target variable if applicable\n",
    "X = df.drop(columns=['market_trend2'])  # Assuming 'target_variable' is the column to be predicted\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA to reduce dimensionality\n",
    "n_components = 2  # Specify the number of principal components to retain\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create a DataFrame with the reduced dimensionality features\n",
    "df_pca = pd.DataFrame(X_pca, columns=[f'PC{i}' for i in range(1, n_components + 1)])\n",
    "\n",
    "# Concatenate the reduced features with the target variable if applicable\n",
    "# final_df = pd.concat([df_pca, df['target_variable']], axis=1)\n",
    "\n",
    "print(df_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a0daa",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578c33f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63110d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd00ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column1']=[1, 5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76872f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column1\n",
       "0        1\n",
       "1        5\n",
       "2       10\n",
       "3       15\n",
       "4       20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc39715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df.columns:\n",
    "    df[feature]=(df[feature]-df[feature].min())/(df[feature].max()-df[feature].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85872cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    column1\n",
       "0  0.000000\n",
       "1  0.210526\n",
       "2  0.473684\n",
       "3  0.736842\n",
       "4  1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18081a10",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c11d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To perform feature extraction using PCA for the given dataset with features \n",
    "# [height, weight, age, gender, blood pressure], we need to follow these steps:\n",
    "\n",
    "# Step 1: Standardize the data: It is essential to standardize the data (mean = 0, standard deviation = 1)\n",
    "#         before applying PCA, as the algorithm is sensitive to the scale of the features.\n",
    "\n",
    "# Step 2: Calculate the covariance matrix: Compute the covariance matrix of the standardized data. The covariance matrix \n",
    "#         represents the relationships between the features.\n",
    "\n",
    "# Step 3: Calculate the eigenvectors and eigenvalues: Find the eigenvectors and eigenvalues of the covariance matrix. \n",
    "#         These will be used to determine the principal components.\n",
    "\n",
    "# Step 4: Sort the eigenvalues: Sort the eigenvalues in descending order to identify the most significant principal \n",
    "#         components. The principal components corresponding to the largest eigenvalues capture the most variance in the data.\n",
    "\n",
    "# Step 5: Select the number of principal components to retain: Decide on the number of principal components to retain based \n",
    "#         on the amount of variance explained by each component. A common approach is to choose components that explain a significant portion (e.g., 95% or 99%) of the total variance.\n",
    "\n",
    "# Now, let's assume that we have performed PCA, and the sorted eigenvalues in descending order are as follows:\n",
    "\n",
    "# Eigenvalues: [4.8, 3.2, 1.9, 0.5, 0.1]\n",
    "\n",
    "# In this example, we have five original features. The total variance in the data is the sum of all eigenvalues:\n",
    "\n",
    "# Total Variance = 4.8 + 3.2 + 1.9 + 0.5 + 0.1 = 10.5\n",
    "\n",
    "# To decide how many principal components to retain, we can look at the cumulative explained variance:\n",
    "\n",
    "# Cumulative Explained Variance = [4.8, (4.8 + 3.2), (4.8 + 3.2 + 1.9), (4.8 + 3.2 + 1.9 + 0.5), (4.8 + 3.2 + 1.9 + 0.5 + 0.1)] = [4.8, 8.0, 9.9, 10.4, 10.5]\n",
    "\n",
    "# By retaining the first three principal components, we can explain approximately 9.9 out of 10.5 total variance in the data, \n",
    "# which is about 94.3%. Depending on the desired level of variance retention and the application, you may choose to retain\n",
    "# more or fewer principal components.\n",
    "\n",
    "# So, to retain a substantial amount of information while reducing dimensionality, we would choose to retain three principal\n",
    "# components for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b662b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
